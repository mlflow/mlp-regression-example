# `pipeline.yaml` is the main configuration file for an MLflow Pipeline.
# Required pipeline parameters should be defined in this file with either concrete values or
# variables such as {{ INGEST_DATA_LOCATION }}.

# Variables must be dereferenced in a profile YAML file, located under `profiles/`.
# See `profiles/local.yaml` for example usage. One may switch among profiles quickly by
# providing a profile name such as `local` in the Pipeline object constructor:
# `p = Pipeline(profile="local")`
#
# NOTE: YAML does not support tabs for indentation. Please use spaces and ensure that all YAML
# files are properly formatted.

template: "classification/v1"
# Specifies the name of the column containing targets / labels for model training and evaluation
target_col: "species"
# Sets the primary metric to use to evaluate model performance. This primary metric is used
# to sort MLflow Runs corresponding to the pipeline in the MLflow Tracking UI
primary_metric: "f1_score"
positive_class: "Iris-setosa"
steps:
  ingest: {{INGEST_CONFIG}}
  split:
    # Train/validation/test split ratios
    split_ratios: {{SPLIT_RATIOS|default([0.75, 0.125, 0.125])}}
    # Specifies the method to use to perform additional cleaning on split datasets
    # Note that arbitrary transformations should go into the transform step
    post_split_filter_method: steps.split.create_dataset_filter
  transform:
    # Specifies the method that defines the data transformations to apply during model inference
    transformer_method: steps.transform.transformer_fn
  train:
    using: estimator_spec
    # Specifies the method that defines the estimator type and parameters to use for model training
    estimator_method: steps.train.estimator_fn
    estimator_params:
        loss: log_loss
    resampling_minority_percentage: 0.5
  evaluate:
    # Sets performance thresholds that a trained model must meet in order to be eligible for
    # registration to the MLflow Model Registry
    validation_criteria:
      - metric: f1_score
        threshold: 10
  register:
    # Indicates whether or not a model that fails to meet performance thresholds should still
    # be registered to the MLflow Model Registry
    allow_non_validated_model: false
  ingest_scoring: {{INGEST_SCORING_CONFIG}}
  predict:
    output: {{PREDICT_OUTPUT_CONFIG}}
    # model_uri: "models/model.pkl"

# Defines custom performance metrics to compute during model training and evaluation
custom_metrics:
